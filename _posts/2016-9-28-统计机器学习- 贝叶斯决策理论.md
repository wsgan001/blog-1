---
layout: post
title: 统计机器学习： 贝叶斯决策理论
tags: [统计机器学习]
comments: true
share: true
---



### Bayes Introduction

- 最大后验分类（MAP）

  ![](http://ww4.sinaimg.cn/large/801b780ajw1f8s1ndwu5xj219y0e8wi7.jpg)

  - 估计出条件概率密度函数，就能较好的推算后验概率了


- 贝叶斯决策
  - 最小错误率准则
    - 以后验概率为判决函数 
    - This produces the optimal performance: minimum probability of error:  $$p_e = 1-p(C_i \mid x)$$
    - 满足如上准则的分类器就叫做贝叶斯分类
  - 最小风险准则
    - 简单说就是采取不同的决策有着不同的风险权重，在决策的情况下上乘上相应风险就行
  - 贝叶斯决策的三个前提
    - 类别数确定
    - 各类先验概率$$P(C_i)$$已知
    - 各类的条件概率密度函数$$p(x\mid C_i)$$已知
  - 我们需要做的事
    - 基于样本估计$$P(C_i)$$和$$p(x\mid C_i)$$
    - 基于样本直接确定判别函数



已知先验分布和观测值的类条件分布，贝叶斯决策理论是最优的

决策：样本空间到决策空间到**映射**



### 基于最小错误率的Bayes决策

- 条件错误率$${P(e\mid x)}$$


$$
  P(e|x) =
  \begin{cases}
  P(w_2|x) = 1-P(w_1|x)&& x \in w_1\cr
  P(w_1|x) = 1-P(w_2|x)&& x \in w_2\cr
  \end{cases}
$$


#### 最小错误率决策

- 每个决策的条件错误率


$$
P(e|x) = 1-P(w_i|x) \  \ ,if \   x \in w_i
$$

- 决策


$$
  D(x) = arg \ max_{i}P(w_i|x)
$$

Bayes 公式

$$
P(w_i|x) = \dfrac{P(x|w_i)P(w_i)}{P(x)}=\dfrac{P(x|w_i)P(w_i)}{\sum_{i}P(x|w_i)P(w_i)}
$$

其中：$$P(w_i)$$先验概率，$$P(x \mid w_i)$$条件概率

#### Note

- 比较大小不需要计算$$P(x)$$

- 常常做取对数处理


$$
ln(P(x|w_i)P(w_i)) = ln(P(x|w_i))+ln(P(w_i))
$$

### 基于最小风险的Bayes决策

>  决策要考虑决策可能引起的**损失** [例如医疗误诊]

考虑各种错误造成损失不同时的一种最优决策，就是所谓的最小风险贝叶斯决策。设对于实际状态为$$w_j$$的向量x采取决策$$α_i$$所带来的损失为

$$
λ(α_i,w_j),i=1,...,k,j=1,...,c
$$

1. 利用贝叶斯公式计算后验概率

$$
P(w_j|x)=\frac{P(x|w_j)P(w_j)}{ \sum_{i=1}^{c}P(x|w_i)P(w_i)},j=1,...,c
$$

2. 利用决策表，计算条件风险

$$
R(α_i|x)=∑_{j=1}^{c}λ(α_i|w_j)P(w_j|x),i=1,...k
$$

3. 决策：选择风险最小的决策

$$
α=argmin_{i=1,...,k}R(α_i|x)
$$

PS：两类问题正态模型的决策面

$$
ln(P(x|w_1)P(w_1)) = ln(P(x|w_2)P(w_2))
$$


