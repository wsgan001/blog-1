---
layout: post
title: 统计机器学习：BAYES DECISION THEORY
tags: [统计机器学习]
---



### Outline

1. 基于最小**错误率**
2. 基于最小**风险**
3. **正态分布**的最小错误率

----



已知先验分布和观测值的类条件分布，贝叶斯决策理论是最优的

决策：样本空间到决策空间到**映射**



### 基于最小错误率的Bayes决策

- 条件错误率$${P(e\mid x)}$$


  $$
  P(e|x) =
  \begin{cases}
  P(w_2|x) = 1-P(w_1|x)&& x \in w_1\cr
  P(w_1|x) = 1-P(w_2|x)&& x \in w_2\cr
  \end{cases}
  $$








#### 最小错误率决策

- 条件错误率


  $$
  P(e|x) = 1-max_{i}P(w_i|x)
  $$

- 错误率

  $$
  P(e) = E(P(e|x))
  $$

- 决策


  $$
  D(x) = arg \ max_{i}P(w_i|x)
  $$







Bayes 公式

$$
P(w_i|x) = \dfrac{P(x|w_i)P(w_i)}{P(x)}=\dfrac{P(x|w_i)P(w_i)}{\sum_{i}P(x|w_i)P(w_i)}
$$

其中：$$P(w_i)$$先验概率，$$P(x|w_i)$$条件概率



#### Note

- 比较大小不需要计算$$P(x)$$

- 常常做取对数处理


  $$
  ln(P(x|w_i)P(w_i)) = ln(P(x|w_i))+ln(P(w_i))
  $$









### 基于最小风险的Bayes决策

>  决策要考虑决策可能引起的**损失** [例如医疗误诊]

考虑各种错误造成损失不同时的一种最优决策，就是所谓的最小风险贝叶斯决策。设对于实际状态为$$w_j$$的向量x采取决策$$α_i$$所带来的损失为

$$
λ(α_i,w_j),i=1,...,k,j=1,...,c
$$

1. 利用贝叶斯公式计算后验概率

$$
P(w_j|x)=\frac{P(x|w_j)P(w_j)}{ \sum_{i=1}^{c}P(x|w_i)P(w_i)},j=1,...,c
$$

2. 利用决策表，计算条件风险

$$
R(α_i|x)=∑_{j=1}^{c}λ(α_i|w_j)P(w_j|x),i=1,...k
$$

3. 决策：选择风险最小的决策

$$
α=argmin_{i=1,...,k}R(α_i|x)
$$

PS：两类问题正态模型的决策面

$$
ln(P(x|w_1)P(w_1)) = ln(P(x|w_2)P(w_2))
$$


