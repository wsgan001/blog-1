---
layout: post
title: 机器学习：模型评估与选择
tags: [Machine Learning]
comments: true
share: true
---


### 模型评估方法

#### 1. 留出法（hold-out）

**方法**：直接将数据集D划分为两个互斥的集合，训练集合S和测试集合T，在S上训练模型，用T来评估其测试误差

**注意**：训练／测试集的划分要尽可能保持数据分布的一致性，避免因为数据划分过程引入额外的偏差而对最终结果产生影响

**缺点与改进**：单次使用留出法得到的估计往往不够稳定可靠，在使用留出法时，一般要采用若干次随机划分、重复进行实验评估后取平均值作为留出法的评估结果

**实际运用**：实际中一般将大约2/3～4/5的样本用于训练，剩余样本用于测试

#### 2. 交叉验证法（cross validation）

**方法**：先将数据集D划分为k个大小相似的互斥子集.每个子集$D_i$都尽可能保持数据分布的一致性，即从D中通过分层采样得到 .然后每次用k-1个子集的并集作为训练集，余下的那个子集作为测试集，这样就可以获得k组训练／测试集，从而可以进行k次训练和测试，最终返回的是这k个测试结果的均值

**实际运用**：一般而言k的取值为10，常用的还有5、20等

**原理图**: 

![](http://ww2.sinaimg.cn/large/006y8lVajw1f8j19hjrjcj30jp0mu767.jpg)



#### 3. 自助法（bootstrapping）

**问题引出**：我们希望评估的是用D训练出来的模型，但是留出法和交叉验证法中，由于保留了一部分样本用于测试，因此实际评估的模型所使用的训练集比D小，这必然会引入一些因训练样本规模不同而导致的估计偏差，为此提出自助法.

**方法**：它以自助采样(bootstrap sampling)为基础.给定包含m个样本的数据集D，我们对它进行采样产生数据集 $$D^{’}$$：每次随机从D中挑选出一个样本，将其拷贝放入$$D^{'}$$, 然后再将该样本放回初始数据集D中，使得该样本在下次采样时仍有可能被采样到；这个过程重复执行m次后，我们就得到可包含m个样本数据的数据集$$D^{'}$$,这就是自助采样的结果.样本在m次采样中始终不被采到到概率为
$$
\lim _{m\rightarrow \infty }\left( 1-\dfrac {1}{m}\right) ^{m}\rightarrow \dfrac{1}{e}
$$
由此可知通过自助采样，初始数据集D中约有36.8%的样本未出现在采样数据集$$D^{'}$$中.于是我们可将$$D^{'} $$用作训练集，$$D\backslash D^{'}$$用作测试集.

**优缺点**：自助法在数据集较小，难以有效划分训练／测试集时很有用，但是，自助法改变了初始数据集的分布，这会引入估计偏差，所以在数据量足够时，一般采用留出法和交叉验证法.



### 性能度量

#### 1. 错误率（error rate）与精度（accuracy）

错误率定义：
$$
E\left( f;D\right) =\dfrac {1}{m}\sum ^{m}_{i=1}I\left( f\left( x_{i}\right) \neq y_{i}\right)
$$


精度定义：
$$
acc\left( f;D\right) =\dfrac {1}{m}\sum ^{m}_{i=1}I\left( f\left( x_{i}\right) =y_{i}\right) =1-E\left( f;D\right)
$$

#### 2. 准确率（precision）和召回率（recall）

**问题引出**：在现实生活，比如信息检索中，我们往往会关心”检索出的信息中有多少比例是用户感兴趣的“，”用户感兴趣的信息中有多少被检索出来了“，准确率和召回率则比较适用于此类需求的性能度量

绘制如下混淆矩阵（confusion matrix）来进一步定义相关概念

![](http://ww2.sinaimg.cn/large/006y8lVajw1f8j19w5au0j31kw0nnto7.jpg)


准确率定义：
$$
Precision = \dfrac{TP}{TP+FP}
$$

召回率定义：
$$
Recall = \dfrac{TP}{TP+FN}
$$


|                   集合表示                   |                  形象化解释                   |
| :--------------------------------------: | :--------------------------------------: |
| **![](http://ww2.sinaimg.cn/large/006y8lVajw1f8j1a8pjpyj30hw0my401.jpg)** | **![](http://ww1.sinaimg.cn/large/006y8lVajw1f8j1af0m1gj30g009mmxj.jpg)** |

|         准确率与召回率之间的权衡可以使用PR曲线来衡量          |
| :--------------------------------------: |
| ![](http://ww4.sinaimg.cn/large/006y8lVajw1f8j1anpw4dj30at09u0t9.jpg) |

将准确率和召回率相结合可以得到一些更实用的度量方式

F1度量定义：

$$
F1 ＝ \dfrac{2×Precision×Recall}{Precision + Recall}
$$

F1是基于准确率和召回率的**调和平均**定义的

在一些应用中，对准确率和召回率的重视程度不同，例如在商品推销系统中，为了尽可能少打扰用户，更希望推荐内容是用户感兴趣的，此时准确率更重要.而在逃犯信息检索系统中，更希望尽可能少漏掉逃犯，此时召回率比较重要.

将F1一般化可得到$$F_\beta$$的定义：

$$
F_{\beta} = \dfrac{(1+\beta^{2})×Precision×Recall}{(\beta^{2}×Precision)+Recall}
$$

其中$$\beta = 1$$时退化为标准的F1，$$\beta>1$$时对准确率有更大影响，$$\beta<1$$时对召回率有更大影响

#### 3. ROC 与AUC

**ROC Curve**: 在统计中,"受试者工作特征"（receiver operating characteristic），是一幅用于描述在不同的阈值下二分类系统的性能表现的图。该图的横坐标为false positive rate（FPR），纵坐标为true positive rate （TPR）,随着阈值的变化可得到一系列坐标点.

TPR的定义：

$$
TPR ＝ \dfrac{TP}{TP+FN}
$$

FPR的定义：
$$
FPR = \dfrac{FP}{FP+TN}
$$

![](http://ww3.sinaimg.cn/large/006y8lVajw1f8j1aujnm9j30y50hvq7y.jpg)

AUC: Area under the curve 可通过对ROC曲线下各部分的面积求和而得



#### 4. 期望值分析框架

![](http://ww2.sinaimg.cn/large/006y8lVajw1f8j1b2h8u6j30wp0agab0.jpg)

- Confusion Matrix
  $$
  \begin{bmatrix}
      True Positive & False Negative \\  
      False Postive & True Negative\\ 
    \end{bmatrix}
  $$





- Cost Matrix
  $$
  \begin{bmatrix}
  Benefit_{TP} & Cost_{FN} \\
  Cost_{FP} & Benefit_{TN}\\
  \end{bmatrix}
  $$




$$
Expected\_Profit =True Positive×Benefit_{TP}＋False Negative×Cost_{FN}＋False Postive×Cost_{FP}＋True Negative×Benefit_{TN}
$$

#### 5. 偏差与方差

$$
Error ＝ Bias ＋ Variance ＋ Noise
$$

训练集中包含了一系列的点$$(x_1,y_1) , (x_2,y_2) , … , (x_i,y_i),…,(x_n,y_n)$$,我们假定存在一个函数$$y = f(x) + \epsilon$$，其中的$$\epsilon$$的均值为0方差为$$\sigma^{2}$$.我们需要找到一个函数$$\hat{f}(x)$$使它尽可能地毕竟函数$$f(x)$$.

为此我们需要最小化$$(y-\hat{f}(x))^{2}$$，对这个误差的期望进行分解可得：

$$
E[y-\hat{f}(x)^{2}] = Bias[\hat{f}(x)]^{2}+Var[\hat{f}(x)]+\sigma^{2}
$$

其中：

$$
Bias[\hat{f}(x)] = E[\hat{f}(x)-f(x)]
$$

$$
Var[\hat{f}(x)] = E[\hat{f}(x)-E[\hat{f}(x)]^2]
$$

偏差度量了学习算法的期望预测与实际结果的偏离程度，即刻画了学习算法本身的拟合能力

方差度量了同样大小的训练集的变动所导致的学习性能的变化，即刻画了数据扰动所造成的影响

噪声则表达了当前任务上任何学习算法所能达到的期望泛化误差的下界，即刻画了学习问题本身的难度

|          Bias-Variance Dilemma           |
| :--------------------------------------: |
| ![](http://ww4.sinaimg.cn/large/006y8lVajw1f8j1b9o934j30do08lt9a.jpg) |

给定学习任务，在训练不足时，学习器的拟合能力不够强，训练数据的扰动不足以使学习器产生显著变化，此时偏差主导了泛化误差率；随着训练程度的加深，学习器的拟合能力逐渐增强，训练数据发生的扰动逐渐能被学习器学到，方差逐渐主导了泛化误差率；在训练程度足够后，学习器的拟合能力已非常强，训练数据发生的轻微扰动都会导致学习器发生显著变化，若训练数据自身的、非全局的特性被学习器学到了，则将发生过拟合.



